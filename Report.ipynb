{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Learning Project : sequential weighted scheme comparison\n",
    "_Supervisor : Gilles Stoltz (http://stoltz.perso.math.cnrs.fr/enseignements.html)_\n",
    "\n",
    "_Author : Hugo Vallet (https://uk.linkedin.com/in/hugovallet)_\n",
    "\n",
    "_Course : Learning and sequential optimization, Data Science track, Paris-Saclay University_\n",
    "\n",
    "## Intoduction\n",
    "In this report, we will test multiple weighting schemes for sequential learning problems. As a reminder, the sequential learning setup is the following :\n",
    "- We have a set of $N$ \"experts\", or predictors, $N \\in \\mathbb{N}$\n",
    "- We get the data \"online\", meaning that we do not have access directly to a batch : the examples (data points in $\\mathbb{R}^d$) are coming iteratively in time.\n",
    "- At each step $t$, for a given data point $x_t$, the prediction is a weighted sum of the individual predictions of the  experts. \n",
    "\n",
    "The main challenge here is to find the best choice of weights at a time t, given the data (and the associated errors of the experts) seen in the past.\n",
    "\n",
    "## Dataset\n",
    "Here, I consider first a toy regression problem generated using the library Sklearn. This dataset is composed of 10000 iid obeservations in $\\mathbb{R}^{15}$ following a Gaussian distribution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "from sklearn.datasets import make_regression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "py.sign_in('hugovallet', '30sc9ihac8')\n",
    "\n",
    "#Generate the dataset\n",
    "data,y = make_regression(n_samples = 10000, n_features = 15, n_informative = 15, n_targets = 1 , bias = 0, noise=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choice of experts and methodology\n",
    "The aim of the report is to study the behaviour of the Ridge-weighting and EWA algorithms on a given set of predictors for an incoming flow of data. Hence, we are not really interested in optimizing the choice of experts. Finally, these experts are fixed at the beginning of the problem : they are not intrinsectly modified during the online process, only their weights are updated.\n",
    "\n",
    "With this setup, I created a set of random trees that I will use as experts. The trees are generated using a random-forest training approach :\n",
    "\n",
    "For each tree :\n",
    "- Select randomly a set of features on which the tree will be trained\n",
    "- Construct the tree splitting iteratively on a random subset of this features. The split is chosen with a entropy-based criterion : the chosen split is the one maximizing the \"information\" gain.\n",
    "\n",
    "I use half of my data for this initial training of the experts and I keep the remaining half for the study of the online weighting algorithms (Ridge and EWA). This approach seems valid in the sens that :\n",
    "- The datapoints follow the same distribution. Thus, theorically, the experts learnt during the first phase are relevant for the sequential problem.\n",
    "- Because of the random forest procedure (decribed above) the trees generated are really of variable efficiency. Some of them, which are based on very informative features, perform a lot better than others. Thus, finding a good way to average their predictions (and not taking just the basic average, as used in classical random forest prediction) is relevant.\n",
    "\n",
    "### First phase : training of the experts (generating the trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted R-squared score :  0.321646503209\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2, random_state=42)\n",
    "reg = RandomForestRegressor(n_estimators=50, max_features='sqrt')\n",
    "reg.fit(X_train,y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "print \"Adjusted R-squared score : \",r2_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using random forests, it is always interesting to check the features which contribute the most is the model. Sklearn implementation proposes a keys-in-hand method to compute an individual score of the different features which is directly linked to the number of times the features where selected for a split (i.e. how informative they are)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "PlotlyError",
     "evalue": "Request throttled. You've created/updated more charts than your allowed limit of 50/day. You may either wait one day or upgrade your account. Visit https://plot.ly/settings/subscription/ to upgrade.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPlotlyError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-210-5355a77fed39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      6\u001b[0m \u001b[0mtrace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'importances'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Hugo\\Desktop\\WinPython-2.7.10.3\\python-2.7.10.amd64\\lib\\site-packages\\plotly\\plotly\\plotly.pyc\u001b[0m in \u001b[0;36miplot\u001b[1;34m(figure_or_data, **plot_options)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'auto_open'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mplot_options\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[0mplot_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'auto_open'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m     \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigure_or_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mplot_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigure_or_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Hugo\\Desktop\\WinPython-2.7.10.3\\python-2.7.10.amd64\\lib\\site-packages\\plotly\\plotly\\plotly.pyc\u001b[0m in \u001b[0;36mplot\u001b[1;34m(figure_or_data, validate, **plot_options)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[0mplot_options\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_plot_option_logic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplot_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_send_to_plotly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mplot_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mplot_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'auto_open'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Hugo\\Desktop\\WinPython-2.7.10.3\\python-2.7.10.amd64\\lib\\site-packages\\plotly\\plotly\\plotly.pyc\u001b[0m in \u001b[0;36m_send_to_plotly\u001b[1;34m(figure, **plot_options)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1403\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'error'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1404\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPlotlyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1406\u001b[0m     \u001b[1;31m# Check if the url needs a secret key\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPlotlyError\u001b[0m: Request throttled. You've created/updated more charts than your allowed limit of 50/day. You may either wait one day or upgrade your account. Visit https://plot.ly/settings/subscription/ to upgrade."
     ]
    }
   ],
   "source": [
    "feature_importances = reg.feature_importances_\n",
    "trace = go.Bar(\n",
    "         x=[(\"Feature\"+str(i)) for i in range(len(feature_importances))],\n",
    "         y=feature_importances\n",
    ")\n",
    "trace = [trace]\n",
    "py.iplot(trace, layout=layout, filename='importances')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this graph, it is easy to intuit that the trees which are not based on the features 5 and 14, for instance, will be less efficient than the other ones. To check that, let's plot the individual errors of our trees in the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEACAYAAABYq7oeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAF4JJREFUeJzt3WGMXeV95/HvD1xC0gCCNrZXNjSkYApR1UAlryp21emy\nhZBKwBtYR6tiFlcrLayC1FW1OG9wXqya8CaOtAJpFRqM1dR1kFJcCYGDvNaqEgluQwqKXTPaChYb\nPLS4UGUjRUD+++I+3rmeM/bMXF/P3Dv3+5FGnPmf8zz3OWdm7u+c55xrUlVIktTvgpUegCRp9BgO\nkqQOw0GS1GE4SJI6DAdJUofhIEnqWDAckmxK8nKSH7b/vp/kS0kuT7I/ydEkzye5rK/N9iTTSY4k\nubWvflOSV5K8lmRnX/2iJHtamxeTXDX8XZUkLdaC4VBVr1XVjVV1E/CbwP8Fvgs8DLxQVdcBB4Dt\nAEluAO4BrgduBx5Lktbd48C2qtoEbEpyW6tvA05W1bXATuDRYe2gJGnpljqt9G+B/11VbwJ3Arta\nfRdwV1u+A9hTVR9W1evANLA5yXrgkqo61LZ7qq9Nf19PA7csdUckScOz1HD4d8C32/K6qpoBqKoT\nwNpW3wC82dfmeKttAI711Y+12mltquoj4L0kVyxxbJKkIVl0OCT5BXpXBd9ppbn/7sYw/x2OLLyJ\nJOl8WbOEbW8H/qaq/rF9P5NkXVXNtCmjd1r9OHBlX7uNrXamen+bt5JcCFxaVSfnDiCJ/xCUJA2g\nqpZ00r2UaaUvAn/W9/0+4L62vBV4pq++pT2BdDVwDfBSm3p6P8nmdoP63jlttrblu+nd4J5XVflV\nxSOPPLLiYxiVL4+Fx8JjcfavQSzqyiHJJ+jdjP6PfeWvAXuT3A+8Qe8JJarqcJK9wGHgA+CBmh3d\ng8CTwMXAs1X1XKs/AexOMg28C2wZaG8kSUOxqHCoqp8Cn5pTO0kvMObb/o+BP56n/jfAr89T/xkt\nXCRJK89PSI+pqamplR7CyPBYzPJYzPJYnJsMOh+1EpLUOI1XkkZBEuo83pCWJE0Iw0GS1GE4SJI6\nDAdJUofhIEnqMBwkSR2GgySpw3CQJHUYDpKkDsNBktRhOEiSOgwHSVKH4SBJ6jAcJEkdhoMkqcNw\nkCR1GA6SpA7DQZLUYThIkjoMB0kjYf36T5PktK/16z+90sOaWKmqlR7DoiWpcRqvpMVLAsz9+w7+\nzZ+7JFRVltJmUVcOSS5L8p0kR5L8OMm/THJ5kv1JjiZ5PsllfdtvTzLdtr+1r35TkleSvJZkZ1/9\noiR7WpsXk1y1lJ2QJA3XYqeVvgE8W1XXA78B/B3wMPBCVV0HHAC2AyS5AbgHuB64HXgsvVMCgMeB\nbVW1CdiU5LZW3wacrKprgZ3Ao+e8Z5KkgS0YDkkuBf51VX0LoKo+rKr3gTuBXW2zXcBdbfkOYE/b\n7nVgGticZD1wSVUdats91demv6+ngVvOaa8kSedkMVcOVwP/mORbSX6Y5H8k+QSwrqpmAKrqBLC2\nbb8BeLOv/fFW2wAc66sfa7XT2lTVR8B7Sa4YcJ8kSedozSK3uQl4sKr+OsnX6U0pzb1LNMy7Rme8\ncbJjx47/vzw1NcXU1NQQX1aSxt/Bgwc5ePDgOfWx4NNKSdYBL1bVZ9r3/4peOPwqMFVVM23K6H9W\n1fVJHgaqqr7Wtn8OeAR449Q2rb4F+O2q+k+ntqmqHyS5EHi7qtbOMxafVpJWKZ9WOn/Oy9NKbero\nzSSbWukW4MfAPuC+VtsKPNOW9wFb2hNIVwPXAC+1qaf3k2xuN6jvndNma1u+m94NbknSClnU5xyS\n/AbwTeAXgL8H/gNwIbAXuJLeVcE9VfVe2347vSeQPgAeqqr9rf6bwJPAxfSefnqo1T8G7AZuBN4F\ntrSb2XPH4ZWDtEot55XD+vWfZmbmjdNq69b9CidOvD701xoFg1w5+CE4aQkm7U1lOS1nOEzaFNZ5\n+xCcVj//6YLF6QVDnfY1Nyyk1cBwEDA6b3qGlDQaDAeNlFEJqXFluK4Oo/BzNBxG2Hy/IP6xd43C\nH9KoGPVwHfRnNWk/41H4OXpDeoTNf9MMzseNs1G5QTfIOM7WZtg3kEflOJ3JOI9v0HXDHscoOB/7\n6w3pOZbz7HulX2uh15nEK5FROAOTxtGqv3JY+bPvwV/rbP31DOMMe/D+zodhXzl4xgnjMj5/jrO8\nchiiSZuTXE4eW+nsVuPfyKoJB6cPzp/VeGxXegpwNbx5rEaD/qzO9Dcyzj/7VTOtdKbLsJ7RnlY6\n003T2V+4bn89yzOtNOqfXB1kOqJn6T+r4Y1v4XaDGOfpklGYVuoZ3u/FsPtzWmkELOdl4mo8Mx+2\ncT4DGxWrcepDs4b9N+KVw5lfa97+zscZ4iBjn3/d6r1ymH98Z1s3/lcOgzyGu5xn34PwyuHc+juX\nv2+vHDTyPIOddbZjMepXlGcau/dzVoexu3KYWzt1JjXqye2Vw0LjGPxMf/5143HlMP84Bj/uo372\nPf+6wa8czvZao3CmP+z+vHI4q9E9kzqb5Txb9sxc0rkaw3AYT8s5RTDq0xEaH55ojJblnEYbw2ml\nyZk+mL/N6PTntNK5tDnbOEZnWmkUflZOKy2uv4XWTcC0ksaBNwqlsxv1q7KJDgffwM6f+aa2nN4a\nTav172DU33xHffp3osPBN7BzN+p/gMtlnB/fXK1/B6P+5jvqJvqew9LXec9htYz9bP0t91zwKB+L\nUehvVMa+nI+je89BkjSSDAdpDqfKNJ9J+71YVDgkeT3J3yZ5OclLrXZ5kv1JjiZ5PsllfdtvTzKd\n5EiSW/vqNyV5JclrSXb21S9Ksqe1eTHJVcPcSWkpnKvWfCbt92KxVw4/B6aq6saq2txqDwMvVNV1\nwAFgO0CSG4B7gOuB24HH0ptAA3gc2FZVm4BNSW5r9W3Ayaq6FtgJPHqO+yVJOgeLDYfMs+2dwK62\nvAu4qy3fAeypqg+r6nVgGticZD1wSVUdats91demv6+ngVuWshOSpOFabDgU8L0kh5L8Qautq6oZ\ngKo6Aaxt9Q3Am31tj7faBuBYX/1Yq53Wpqo+At5LcsUS90WSNCRrFrndzVX1dpJPAfuTHKX7zNQw\nn4k9yyNXO/qWp4b4kot3pn9nX5JGw8H2NbhFhUNVvd3++w9J/gLYDMwkWVdVM23K6J22+XHgyr7m\nG1vtTPX+Nm8luRC4tKpOzj+aHYsZ8nk13/++c2ZmSY8QS9J5NMXsyfNXBuphwWmlJJ9I8sm2/IvA\nrcCrwD7gvrbZVuCZtrwP2NKeQLoauAZ4qU09vZ9kc7tBfe+cNlvb8t30bnBLklbIYq4c1gHf7X06\nmTXAn1bV/iR/DexNcj/wBr0nlKiqw0n2AoeBD4AH+v7fng8CTwIXA89W1XOt/gSwO8k08C6wZSh7\nJ0kaiP98xgj/swGj3t84j33l+1vO1xrv/sZ57Cvf3+w6//kMSdI5MxwkSR2GgySpw3CQJHUYDpKk\nDsNBktRhOEiSOgwHSVKH4SBJ6jAcJEkdhoMkqcNwkCR1GA6SpA7DQZLUYThIkjoMB0lSh+EgSeow\nHCRJHYaDJKnDcJAkdRgOkqQOw0GS1GE4SJI6Fh0OSS5I8sMk+9r3lyfZn+RokueTXNa37fYk00mO\nJLm1r35TkleSvJZkZ1/9oiR7WpsXk1w1rB2UJC3dUq4cHgIO933/MPBCVV0HHAC2AyS5AbgHuB64\nHXgsSVqbx4FtVbUJ2JTktlbfBpysqmuBncCjA+6PJGkIFhUOSTYCXwC+2Ve+E9jVlncBd7XlO4A9\nVfVhVb0OTAObk6wHLqmqQ227p/ra9Pf1NHDL0ndFkjQsi71y+DrwR0D11dZV1QxAVZ0A1rb6BuDN\nvu2Ot9oG4Fhf/Virndamqj4C3ktyxeJ3Q5I0TGsW2iDJ7wEzVfWjJFNn2bTOsm6pcuZVO/qWp4b4\nkpK0WhxsX4NbMByAm4E7knwB+DhwSZLdwIkk66pqpk0ZvdO2Pw5c2dd+Y6udqd7f5q0kFwKXVtXJ\n+YezYxFDlqRJNsXsyfNXBuphwWmlqvpyVV1VVZ8BtgAHqur3gb8E7mubbQWeacv7gC3tCaSrgWuA\nl9rU0/tJNrcb1PfOabO1Ld9N7wa3JGmFLObK4Uy+CuxNcj/wBr0nlKiqw0n20nuy6QPggao6NeX0\nIPAkcDHwbFU91+pPALuTTAPv0gshSdIKyez79uhLUt1bG6Gq6F2MdNf1zLePg6wb9muNd3/jPPaV\n7285X2u8+xvnsa98f7Prquos93K7/IS0JKnDcJAkdRgOkqQOw0GS1GE4SJI6DAdJUofhIEnqMBwk\nSR2GgySpw3CQJHUYDpKkDsNBktRhOEiSOgwHSVKH4SBJ6jAcJEkdhoMkqcNwkCR1GA6SpA7DQZLU\nYThIkjoMB0lSh+EgSepYMBySfCzJD5K8nOTVJI+0+uVJ9ic5muT5JJf1tdmeZDrJkSS39tVvSvJK\nkteS7OyrX5RkT2vzYpKrhr2jkqTFWzAcqupnwO9U1Y3A54Dbk2wGHgZeqKrrgAPAdoAkNwD3ANcD\ntwOPJUnr7nFgW1VtAjYlua3VtwEnq+paYCfw6LB2UJK0dIuaVqqqn7bFjwFrgALuBHa1+i7grrZ8\nB7Cnqj6sqteBaWBzkvXAJVV1qG33VF+b/r6eBm4ZaG8kSUOxqHBIckGSl4ETwPfaG/y6qpoBqKoT\nwNq2+Qbgzb7mx1ttA3Csr36s1U5rU1UfAe8luWKgPZIknbM1i9moqn4O3JjkUuC7ST5L7+rhtM2G\nOK6cedWOvuWpIb6kJK0WB9vX4BYVDqdU1T8nOQh8HphJsq6qZtqU0Ttts+PAlX3NNrbamer9bd5K\nciFwaVWdnH8UO5YyZEmaQFPMnjx/ZaAeFvO00i+fehIpyceB3wWOAPuA+9pmW4Fn2vI+YEt7Aulq\n4BrgpTb19H6Sze0G9b1z2mxty3fTu8EtSVohi7ly+BfAriQX0AuTP6+qZ5N8H9ib5H7gDXpPKFFV\nh5PsBQ4DHwAPVNWpKacHgSeBi4Fnq+q5Vn8C2J1kGngX2DKUvZMkDSSz79ujL0l1b22EqqJ3MdJd\n1zPfPg6ybtivNd79jfPYV76/5Xyt8e5vnMe+8v3Nrquqs9zL7fIT0pKkDsNBktRhOEiSOgwHSVKH\n4SBJ6jAcJEkdhoMkqcNwkCR1GA6SpA7DQZLUYThIkjoMB0lSh+EgSeowHCRJHYaDJKnDcJAkdRgO\nkqQOw0GS1GE4SJI6DAdJUofhIEnqMBwkSR2GgySpY8FwSLIxyYEkP07yapIvtfrlSfYnOZrk+SSX\n9bXZnmQ6yZEkt/bVb0rySpLXkuzsq1+UZE9r82KSq4a9o5KkxVvMlcOHwB9W1WeB3wIeTPJrwMPA\nC1V1HXAA2A6Q5AbgHuB64HbgsSRpfT0ObKuqTcCmJLe1+jbgZFVdC+wEHh3K3kmSBrJgOFTViar6\nUVv+CXAE2AjcCexqm+0C7mrLdwB7qurDqnodmAY2J1kPXFJVh9p2T/W16e/raeCWc9kpSdK5WdI9\nhySfBj4HfB9YV1Uz0AsQYG3bbAPwZl+z4622ATjWVz/Waqe1qaqPgPeSXLGUsUmShmfNYjdM8kl6\nZ/UPVdVPktScTeZ+fy5y5lU7+panhviSkrRaHGxfg1tUOCRZQy8YdlfVM608k2RdVc20KaN3Wv04\ncGVf842tdqZ6f5u3klwIXFpVJ+cfzY7FDFmSJtgUsyfPXxmoh8VOK/0JcLiqvtFX2wfc15a3As/0\n1be0J5CuBq4BXmpTT+8n2dxuUN87p83Wtnw3vRvckqQVsuCVQ5KbgX8PvJrkZXrTR18GvgbsTXI/\n8Aa9J5SoqsNJ9gKHgQ+AB6rq1JTTg8CTwMXAs1X1XKs/AexOMg28C2wZzu5JkgaR2fft0de7zzF3\nvKGq6F2MdNf1zLePg6wb9muNd3/jPPaV7285X2u8+xvnsa98f7Prquos93K7/IS0JKnDcJAkdRgO\nkqQOw0GS1GE4SJI6DAdJUofhIEnqMBwkSR2GgySpw3CQJHUYDpKkDsNBktRhOEiSOgwHSVKH4SBJ\n6jAcJEkdhoMkqcNwkCR1GA6SpA7DQZLUYThIkjoMB0lSh+EgSepYMBySPJFkJskrfbXLk+xPcjTJ\n80ku61u3Pcl0kiNJbu2r35TklSSvJdnZV78oyZ7W5sUkVw1zByVJS7eYK4dvAbfNqT0MvFBV1wEH\ngO0ASW4A7gGuB24HHkuS1uZxYFtVbQI2JTnV5zbgZFVdC+wEHj2H/ZEkDcGC4VBVfwX805zyncCu\ntrwLuKst3wHsqaoPq+p1YBrYnGQ9cElVHWrbPdXXpr+vp4FbBtgPSdIQDXrPYW1VzQBU1Qlgbatv\nAN7s2+54q20AjvXVj7XaaW2q6iPgvSRXDDguSdIQrBlSPzWkfgBy9tU7+panhviykrRaHGxfgxs0\nHGaSrKuqmTZl9E6rHweu7NtuY6udqd7f5q0kFwKXVtXJM7/0jgGHLEmTYorZk+evDNTDYqeVwuln\n9PuA+9ryVuCZvvqW9gTS1cA1wEtt6un9JJvbDep757TZ2pbvpneDW5K0gha8ckjybXoR9EtJ/g/w\nCPBV4DtJ7gfeoPeEElV1OMle4DDwAfBAVZ2acnoQeBK4GHi2qp5r9SeA3UmmgXeBLcPZNUnSoDL7\n3j36klT39kaoKnoXJN11PfPt4yDrhv1a493fOI995ftbztca7/7Geewr39/suqpa4H7u6fyEtCSp\nw3CQJHUYDpKkDsNBktRhOEiSOgwHSVKH4SBJ6jAcJEkdhoMkqcNwkCR1GA6SpA7DQZLUYThIkjoM\nB0lSh+EgSeowHCRJHYaDJKnDcJAkdRgOkqQOw0GS1GE4SJI6DAdJUsfIhEOSzyf5uySvJfmvKz0e\nSZpkIxEOSS4A/jtwG/BZ4ItJfm1lRyVJk2skwgHYDExX1RtV9QGwB7hzhcckSRNrVMJhA/Bm3/fH\nWk2StAJGJRwkSSNkzUoPoDkOXNX3/cZWm0e6leSM685eX/q6Yb/WOPc3zmMfhf6W87XGub9xHvso\n9DeoVNXQOht4EMmFwFHgFuBt4CXgi1V1ZEUHJkkTaiSuHKrqoyT/GdhPb6rrCYNBklbOSFw5SJJG\ny9jckJ7kD8kleSLJTJJX+mqXJ9mf5GiS55NctpJjXA5JNiY5kOTHSV5N8qVWn8Rj8bEkP0jycjsW\nj7T6xB2LU5JckOSHSfa17yfyWCR5Pcnftt+Nl1ptycdiLMLBD8nxLXr73u9h4IWqug44AGxf9lEt\nvw+BP6yqzwK/BTzYfg8m7lhU1c+A36mqG4HPAbcn2cwEHos+DwGH+76f1GPxc2Cqqm6sqs2ttuRj\nMRbhwIR/SK6q/gr4pznlO4FdbXkXcNeyDmoFVNWJqvpRW/4JcITek20TdywAquqnbfFj9O4fFhN6\nLJJsBL4AfLOvPJHHgt4jS3Pf25d8LMYlHPyQXNfaqpqB3psmsHaFx7Osknya3hnz94F1k3gs2jTK\ny8AJ4HtVdYgJPRbA14E/oheQp0zqsSjge0kOJfmDVlvysRiJp5U0FBPzZEGSTwJPAw9V1U+SzN33\niTgWVfVz4MYklwLfTfJZuvu+6o9Fkt8DZqrqR0mmzrLpqj8Wzc1V9XaSTwH7kxxlgN+LcblyWMKH\n5CbGTJJ1AEnWA++s8HiWRZI19IJhd1U908oTeSxOqap/Bg4Cn2cyj8XNwB1J/h74M+DfJNkNnJjA\nY0FVvd3++w/AX9Cbll/y78W4hMMh4Jokv5LkImALsG+Fx7Tcwukff9wH3NeWtwLPzG2wSv0JcLiq\nvtFXm7hjkeSXTz1xkuTjwO/Suwczcceiqr5cVVdV1WfovTccqKrfB/6SCTsWST7RrqxJ8ovArcCr\nDPB7MTafc0jyeeAbzH5I7qsrPKRlk+TbwBTwS8AM8Ai9M4LvAFcCbwD3VNV7KzXG5ZDkZuB/0ftl\nr/b1ZXqfqN/LZB2LX6d3Y/GC9vXnVfXfklzBhB2Lfkl+G/gvVXXHJB6LJFcD36X3t7EG+NOq+uog\nx2JswkGStHzGZVpJkrSMDAdJUofhIEnqMBwkSR2GgySpw3CQJHUYDpKkDsNBktTx/wCSeIj+aFGc\ndwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2d77aac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "trees = reg.estimators_\n",
    "errors = []\n",
    "for tree in trees :\n",
    "    error = mean_squared_error(y_test,tree.predict(X_test))\n",
    "    errors.append(error)\n",
    "    \n",
    "plt.figure()\n",
    "plt.bar(np.arange(len(errors)),errors)\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the real value of series to predict and the prediction made by a uniform average of the predictions of the trees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~hugovallet/4.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace1 = go.Scatter(x = np.arange(len(y_test)),y = y_test,name = \"Real value\")\n",
    "trace2 = go.Scatter(x = np.arange(len(y_pred)),y = y_pred, name = \"Predicted value\")\n",
    "trace = [trace1, trace2]\n",
    "py.iplot(trace, filename='prediction VS real value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_weights_3d(matrix):\n",
    "    \"\"\"\n",
    "    Note :\n",
    "    This method is used to create 3D-graphs to plot the errors or weights accross time.\n",
    "    - matrix : an T by N matrix containing the errors or weights of the N predictors for each iteration between 1 and T.\n",
    "    \"\"\"\n",
    "    T,N = matrix.shape\n",
    "    data = []\n",
    "    for n in range(N):\n",
    "        x = np.ones(T)\n",
    "        y = np.arange(T)\n",
    "        z = matrix[:T,n]\n",
    "\n",
    "        trace = go.Scatter3d(\n",
    "        x=n*x,\n",
    "        y=y,\n",
    "        z=z,\n",
    "        mode='Markers',\n",
    "            marker=dict(\n",
    "                size=12,\n",
    "                line=dict(\n",
    "                    color='rgba(217, 217, 217, 0.14)',\n",
    "                    width=0.5   \n",
    "                ),\n",
    "                opacity=0.8,\n",
    "                symbol = \"circle\",\n",
    "            ),\n",
    "\n",
    "        )\n",
    "        data.append(trace)\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title = \"weights accross time\",\n",
    "        margin=dict(l=0, r=0, b=0, t=5),\n",
    "        scene=go.Scene(\n",
    "            xaxis=go.XAxis(title='Expert index'),\n",
    "            yaxis=go.YAxis(title='Time'),\n",
    "            zaxis=go.ZAxis(title='Weight')\n",
    "        )\n",
    "    )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    return py.iplot(fig, filename='simple-3d-scatter')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
